\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{upquote}
\usepackage[margin=20mm]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\newenvironment{statement}[2][Statement]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\usepackage{xcolor}

\usepackage{subfigure}


% Listings package for code rendering (No external dependencies)
\usepackage{listings}  
\usepackage{xcolor}   % Color support
\usepackage{tcolorbox} % Box for better appearance

% Define custom colors for code highlighting
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstset{frame=tb,
    language=Python,
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    keepspaces=true,                 
    numbers=left,       
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
}





\title{Assignment 6}


\author{Author \\
 Wanjing Hu / fng685@alumni.ku.dk  \\
 Shuangcheng Jia / bkg713@alumni.ku.dk/   \\
 Zhigao Yan / sxd343@alumni.ku.dk  \\
} 

\begin{document}
\maketitle

\section{Transformations on images - Translation}
%zhigao
\subsection{}
Translating one pixel to the right means that the value of each point (x,y) in the new image should be taken from the position of one pixel to the left of the original image.

The mathematical expression can be:
 \[
\tilde{I}(x,y) = I\bigl(x - 1,\, y\bigr).
\]
\subsection{}

In the homogeneous coordinate, the transformation matrix for a 1-pixel translation to the right is:
\[
M = 
\begin{pmatrix}
1 & 0 & 1 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}
\]

\[
\begin{pmatrix}
x' \\[6pt]
y' \\[6pt]
1
\end{pmatrix}
=
M
\cdot
\begin{pmatrix}
x \\[6pt]
y \\[6pt]
1
\end{pmatrix}
\quad\Longrightarrow\quad
\tilde{I}(x', y') = I(x, y)
\]
\subsection{}
If we use convolution:
\[
K = 
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{bmatrix}
\]
For Correlation:
\[
K = 
\begin{bmatrix}
0 & 0 & 0 \\
1 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}
\]
\subsection{}
Image size is 17*17, square size is 5*5.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/a6_1.4.png} 
    \caption{Zero-Valued Image}
\end{figure}
\subsection{}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/a6_1.5.png} 
    \caption{Zero-Valued Image after translation}
\end{figure}
I showed the original image as well as the image that was first translated 2 pixels to the right and then 5 pixels down.
\begin{lstlisting}
def translate_image(image, dx=0, dy=0, boundary='symm'):
    
    # Generate horizontal translation kernels
    kernel_x = np.zeros((1, 2*abs(dx)+1))
    kernel_x[0, abs(dx) + dx] = 1  
    print(kernel_x)
    
    # Generate vertical translation kernels
    kernel_y = np.zeros((2*abs(dy)+1, 1))
    kernel_y[abs(dy) + dy, 0] = 1
    print(kernel_y)
    
    # Translation in both directions
    shifted = convolve2d(image, kernel_x, mode='same', boundary=boundary)
    shifted = convolve2d(shifted, kernel_y, mode='same', boundary=boundary)
    return shifted
\end{lstlisting}
The code is to first generate two translational kernels and then convolve the images separately.
Scipy provides three boundary conditions, which are:
'fill': pad input arrays with fillvalue.
'wrap': circular boundary conditions.
'symm': symmetrical boundary conditions.
\subsection{}
\begin{lstlisting}
    def translate_image_homogeneous(image, tx, ty):
    rows, cols = image.shape
    # Create target image (initialised to 0)
    translated = np.zeros_like(image)
    
    # homogeneous coordinate
    T = np.array([[1, 0, tx],
                  [0, 1, ty],
                  [0, 0, 1]])
    
    for i in range(rows):
        for j in range(cols):
            # Find the inverse matrix of homogeneous coordinate and multiply the transformed coordinates.
            x, y, _ = np.linalg.inv(T) @ [i, j, 1]
            # nearest neighbor interpolation
            x_round = int(round(x))
            y_round = int(round(y))
            # Check that the image limit is not exceeded.
            if 0 <= x_round < rows and 0 <= y_round < cols:
                translated[i, j] = image[x_round, y_round]
    
    return translated
\end{lstlisting}
First I would initialise an image the same size as the original and set all the initial values to 0. Then construct homogeneous coordinate and multiply them according to the eq 1.2. Then get the closest coordinates for interpolation, and return an image.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/a6_1.6.png} 
    \caption{Non-integer translations}
\end{figure}


The image on the left is the image that was first shifted 0.6 to the right and then 1.2 down.
\newpage
\subsection{}
\begin{lstlisting}
    def fourier_translate(image, tx, ty):

    # Calculate the frequencies separately and then combine the frequency grids
    rows, cols = image.shape
    u = np.fft.fftfreq(cols)  
    v = np.fft.fftfreq(rows)  
    U, V = np.meshgrid(u, v)  

    # Calculate the Fourier transform
    F = fft2(image)
    
    # Fourier transform translation equation.
    phase_shift = np.exp(-2j * np.pi * (tx * U + ty * V))

    
    F_translated = F * phase_shift

    # Inverse Fourier transform back to the spatial domain
    translated_image = np.real(ifft2(F_translated))

    return translated_image
\end{lstlisting}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/a6_1.7.png} 
    \caption{Fourier transform translation.}
\end{figure}
My code is built based on the following equation:
\[
f(x - a, y - b) \quad \xrightarrow{\mathcal{F}} \quad F(u,v) e^{-i 2\pi (ua + vb)}
\]
It seems to me that this Fourier transform translation method cannot cope with non-integer numbers. As we can see from the image, there is a blurring of the image after the translation, which proves that the pixels are not in the correct position.

\subsection{}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/a6_1.8.png} 
    \caption{Fourier transform translation for real image}
\end{figure}
The method of the Fourier transform can be used for non-integer translations. I applied it to a real image and found that the blurring effect was not too noticeable, and that the out-of-range image was added to the edges after the translation.
I'm guessing that the white square pictures have sharp edges, so that causes a loss of precision in the high frequency components corresponding to the edges, whereas the normal pictures have relatively smooth edges, so the effect is small.
\section{Feature detection and image transforms}
%wanjing
\textbf{Step1 Preprocess}
We apply Gaussian Blur to reduce noise and smooth out variations. We choose a kernel sized (5,5).
\begin{lstlisting}
image = io.imread(image_path, as_gray=True)
blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Kernel size (5,5)
\end{lstlisting}


\textbf{Step2 Corner Detection}
We use Harris Corner Detector to identify key points in the image where intensity changes sharply. The method is set to k to use the Harris response formula, and sigma=1 for standard deviation for Gaussian smoothing. The min distance is set 10 to ensure the detected corners are at least 10 pixels apart. The threshold rel is set to 0.01 to filter weak corner responses.
\begin{lstlisting}
corners_response = corner_harris(blurred_image, method='k', k=0.04, sigma=1)
corners = corner_peaks(corners_response, min_distance=10, threshold_rel=0.01)
\end{lstlisting}

\textbf{Step3 Corner Selection}
The detected points are converted to (x,y) format for processing, and we apply a sorting heuristic  to identify the four primary corners of the label: top-left, top-right, bottom-left, and bottom-right.
\begin{lstlisting}
# Convert (row, col) to (x, y)
corners = np.fliplr(corners)   
# Sort by x, then y
sorted_corners = sorted(corners, key=lambda x: (x[0], x[1])) 
top_left, top_right = sorted_corners[0], sorted_corners[-1]
bottom_left, bottom_right = sorted_corners[1], sorted_corners[-2]
\end{lstlisting}

\textbf{Step4 Estimating Rotation Angle}
The required rotation angle is computed using the atan2 function based on the x-y difference between the top-left and top-right corners. This gives the required rotation angle in degrees, valued -57.28.

\begin{lstlisting}
delta_x = top_right[0] - top_left[0]
delta_y = top_right[1] - top_left[1]
angle = np.arctan2(delta_y, delta_x) * (180.0 / np.pi)  # Convert to degrees
\end{lstlisting}

\textbf{Step5 Image Rotation and Visualization}
Here we plot the detected corners overlayed on the original image. And we display the final rotated image.

The parameter resize=True ensures the entire image remains within frame after rotation. 

Our final result is issued in Figure~\ref{rot}.
\begin{lstlisting}
rotated_image = transform.rotate(image, -angle, resize=True)

fig, ax = plt.subplots(1, 2, figsize=(12, 6))
ax[0].imshow(image, cmap="gray")
ax[0].scatter(corners[:, 0], corners[:, 1], color="red", s=20, label="Corners")
ax[0].set_title("Detected Corners")
ax[0].legend()

ax[1].imshow(rotated_image, cmap="gray")
ax[1].set_title(f"Rotated Image by {-angle:.2f} Degrees")

plt.show()
\end{lstlisting}

% describe the essential steps in your solution including relevant code snippets.

% specify all relevant parameters in the report

% detected label corner points overlayed on top of the image 

% the resulting rotated image and state your estimated rotation angle.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{pics/a6-2.1.png} 
    \caption{Estimated Rotation Angle: -57.28 degrees}
    \label{rot}
\end{figure}


\section{Features, filter banks and texture}
%shuangcheng

\end{document}
